
#type: args

train:
  steps: 30000
  batch_size: 128
  gradient_accumulate_every: 1
  val_interval: 1000
  condition: true
  use_ema: true

  optimizer:
    type: "AdamW"
    lr: 9.0e-5
    weight_decay: 0.

base_model:
  dim: 64
  out_dim: 1
  channels: 1
  z_channels: 1
  condition: true
  self_condition: false

flow:
  sigma_max: 1.0
  sigma_min: 1e-5
  odeint_kwargs:
    method: "euler"
  num_channels: 1
  sampling_timesteps: 5
  default_use_ode: false

test:
  batch_size: 64